{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from random import shuffle\n",
    "import time\n",
    "from nltk.tokenize import TreebankWordTokenizer, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/wiki_movie_plots.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do some minor preprocessing of Genre and Director\n",
    "def genre_clean(x, tokenizer=TreebankWordTokenizer):\n",
    "    x = x.lower()\n",
    "    x = [w for w in tokenizer().tokenize(x) if re.match(\"[A-Za-z]\", w) is not None]\n",
    "    x = \" \".join(x)\n",
    "    return x\n",
    "\n",
    "df[\"Genre\"].fillna(\"Unknown\", inplace=True)\n",
    "df[\"Genre\"] = df[\"Genre\"].apply(lambda x: genre_clean(x))\n",
    "\n",
    "df[\"Director\"].fillna(\"Uknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown            6189\n",
       "drama              6113\n",
       "comedy             4452\n",
       "horror             1207\n",
       "action             1163\n",
       "thriller           1026\n",
       "romance             957\n",
       "western             871\n",
       "crime               579\n",
       "adventure           560\n",
       "crime drama         492\n",
       "musical             472\n",
       "romantic comedy     470\n",
       "science fiction     421\n",
       "comedy drama        360\n",
       "film noir           345\n",
       "mystery             321\n",
       "war                 281\n",
       "animation           269\n",
       "sci-fi              231\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 20 Genres by Frequency\n",
    "df[\"Genre\"].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lowercase, Stem, and Tokenize Plot\n",
    "def stem_tokenize(x, stemmer = PorterStemmer, word_tokenizer=TreebankWordTokenizer, \n",
    "                  sent_tokenizer=sent_tokenize):\n",
    "    \n",
    "    x = x.lower()\n",
    "    sent_tokens = [word_tokenizer().tokenize(s) for s in sent_tokenizer(x)]\n",
    "    stemmed_tokens = [[stemmer().stem(w) for w in s if re.match(\"[A-Za-z]\", w) is not None] \n",
    "                      for s in sent_tokens]\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Plot_tokens\"] = df[\"Plot\"].apply(lambda x: stem_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a list of tagged documents for Doc2Vec training, with each sentence treated as a document\n",
    "\n",
    "Each sentence tag contains a unique index for the subject movie, the director, genre, and origin/ethnicity.\n",
    "The model will find embeddings for all of these tag values\n",
    "\n",
    "\"\"\"\n",
    "tagged_docs = []\n",
    "\n",
    "for i, doc in enumerate(df[\"Plot_tokens\"]):\n",
    "    \n",
    "    genre, origin, director = df.iloc[i][[\"Genre\", \"Origin/Ethnicity\", \"Director\"]]\n",
    "    \n",
    "    movie_indx = \"movie index: %i\" %i\n",
    "    genre = \"genre: %s\" %genre.lower()\n",
    "    origin = \"origin: %s\" %origin\n",
    "    director = \"director: %s\" %director\n",
    "    \n",
    "    for w in doc:\n",
    "        if len(w) > 0:\n",
    "            tagged_docs.append(TaggedDocument(tags = [movie_indx, director, genre, origin], words = w))\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "n_epochs = 50\n",
    "vec_size = 200\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(vector_size = vec_size, \n",
    "                alpha = alpha,\n",
    "                min_count = 50, \n",
    "                dm=1)\n",
    "\n",
    "model.build_vocab(tagged_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Completed in 160 seconds\n",
      "\n",
      "Iteration 1\n",
      "Completed in 175 seconds\n",
      "\n",
      "Iteration 2\n",
      "Completed in 172 seconds\n",
      "\n",
      "Iteration 3\n",
      "Completed in 172 seconds\n",
      "\n",
      "Iteration 4\n",
      "Completed in 171 seconds\n",
      "\n",
      "Iteration 5\n",
      "Completed in 171 seconds\n",
      "\n",
      "Iteration 6\n",
      "Completed in 170 seconds\n",
      "\n",
      "Iteration 7\n",
      "Completed in 169 seconds\n",
      "\n",
      "Iteration 8\n",
      "Completed in 169 seconds\n",
      "\n",
      "Iteration 9\n",
      "Completed in 169 seconds\n",
      "\n",
      "Iteration 10\n",
      "Completed in 169 seconds\n",
      "\n",
      "Iteration 11\n",
      "Completed in 168 seconds\n",
      "\n",
      "Iteration 12\n",
      "Completed in 168 seconds\n",
      "\n",
      "Iteration 13\n",
      "Completed in 210 seconds\n",
      "\n",
      "Iteration 14\n",
      "Completed in 178 seconds\n",
      "\n",
      "Iteration 15\n",
      "Completed in 169 seconds\n",
      "\n",
      "Iteration 16\n",
      "Completed in 168 seconds\n",
      "\n",
      "Iteration 17\n",
      "Completed in 168 seconds\n",
      "\n",
      "Iteration 18\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 19\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 20\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 21\n",
      "Completed in 169 seconds\n",
      "\n",
      "Iteration 22\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 23\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 24\n",
      "Completed in 170 seconds\n",
      "\n",
      "Iteration 25\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 26\n",
      "Completed in 169 seconds\n",
      "\n",
      "Iteration 27\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 28\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 29\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 30\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 31\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 32\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 33\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 34\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 35\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 36\n",
      "Completed in 168 seconds\n",
      "\n",
      "Iteration 37\n",
      "Completed in 168 seconds\n",
      "\n",
      "Iteration 38\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 39\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 40\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 41\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 42\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 43\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 44\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 45\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 46\n",
      "Completed in 166 seconds\n",
      "\n",
      "Iteration 47\n",
      "Completed in 168 seconds\n",
      "\n",
      "Iteration 48\n",
      "Completed in 167 seconds\n",
      "\n",
      "Iteration 49\n",
      "Completed in 167 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for epoch in np.arange(n_epochs):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    print(\"Iteration %i\" %epoch)\n",
    "    model.train(tagged_docs, total_examples= model.corpus_count,\n",
    "                epochs= model.epochs)\n",
    "    \n",
    "    model.alpha -= 0.0002\n",
    "    model.min_alpha = model.alpha\n",
    "    \n",
    "    shuffle(tagged_docs)\n",
    "    print(\"Completed in %i seconds\\n\" %(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"../models/doc2vec.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movies_venv",
   "language": "python",
   "name": "movies_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
