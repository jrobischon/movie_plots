{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle as sk_shuffle\n",
    "from nltk.tokenize import sent_tokenize, TreebankWordTokenizer\n",
    "from gensim.models import word2vec\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Input, LSTM, Dense, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/wiki_movie_plots_deduped.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TODO: **\n",
    "1. Create tf-idf vectorization of documents\n",
    "2. Create generator\n",
    "    * Sample N documents\n",
    "    * Sample keywords (1 to n_max) from each document (selection prob. based on tf-idf)\n",
    "    * Sample k negative documents for each set of search terms\n",
    "    \n",
    "3. Model architecture\n",
    "    * Embedding layer for document\n",
    "    * Embedding layer for keywords\n",
    "    * Concatenate embeddings\n",
    "    * Output layer of 1 unit w/ binary crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(x):\n",
    "    x = x.lower()\n",
    "    s_tokens =  sent_tokenize(x)\n",
    "    tokens = [TreebankWordTokenizer().tokenize(s) for s in s_tokens]\n",
    "    tokens = [[w for w in s if re.match(\"[A-Za-z]\", w) is not None] for s in tokens]\n",
    "    return tokens\n",
    "\n",
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = TreebankWordTokenizer()\n",
    "    def __call__(self, doc):\n",
    "        return [re.sub(\"[^A-Za-z]\", \"\", w.lower()) for w in self.tokenizer.tokenize(doc) \n",
    "                if re.sub(\"[^A-Za-z]\", \"\", w) != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenize each movie plot into a list of sentences, each containing a list of tokens\n",
    "# Return tuple containing (list of tokens, movie index)\n",
    "X_plots = []\n",
    "for i, p in enumerate(df[\"Plot\"]):\n",
    "    sentences = tokenize_text(p)\n",
    "    for s in sentences:\n",
    "        X_plots.append((s, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate plots from movie index\n",
    "x, _ = zip(*X_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train word2vec model\n",
    "wv_model = word2vec.Word2Vec(x, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('creature', 0.8925873637199402),\n",
       " ('beast', 0.7964785099029541),\n",
       " ('demon', 0.7758796215057373),\n",
       " ('monstrous', 0.7614763975143433),\n",
       " ('giant', 0.7488950490951538),\n",
       " ('werewolf', 0.7399545907974243),\n",
       " ('alien', 0.7360496520996094),\n",
       " ('whale', 0.7253955602645874),\n",
       " ('sphere', 0.7226647734642029),\n",
       " ('vampire', 0.7220095992088318)]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_model.wv.most_similar(\"monster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7663202285766602),\n",
       " ('princess', 0.7231383323669434),\n",
       " ('empress', 0.6324298977851868),\n",
       " ('countess', 0.5969557166099548),\n",
       " ('prince', 0.5929268598556519),\n",
       " ('emperor', 0.5760850310325623),\n",
       " ('goddess', 0.5467470288276672),\n",
       " ('consort', 0.5342263579368591),\n",
       " ('count', 0.5263806581497192),\n",
       " ('crown', 0.5165952444076538)]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_model.wv.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of indices for all terms in vocab\n",
    "word2index = {\"<UNK>\": 0}\n",
    "for i, k in enumerate(wv_model.wv.index2word):\n",
    "    word2index[k] = i + 1\n",
    "    \n",
    "embedding = np.zeros((1, wv_model.wv.vectors.shape[1]))\n",
    "embedding = np.concatenate([embedding, wv_model.wv.vectors], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 64131\n",
      "Embedding matrix shape: (64131, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary Size: %i\" %len(word2index))\n",
    "print(\"Embedding matrix shape: %s\" %str(embedding.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def index_lookup(x):\n",
    "    try:\n",
    "        return word2index[x]\n",
    "    except KeyError:\n",
    "        return word2index[\"<UNK>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plots_ind = [([index_lookup(x) for x in sentence], i) for sentence, i in X_plots]\n",
    "X_plots_ind = np.array(X_plots_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(samples, batch_size = 32, n_neg = 5, max_len = 100):\n",
    "    num_samples = samples.shape[0]\n",
    "    \n",
    "    ind = np.arange(num_samples)\n",
    "\n",
    "    while True:\n",
    "        samples = sk_shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            \n",
    "            X_sent = []\n",
    "            X_movie = []\n",
    "            y_out = [] \n",
    "            \n",
    "            # Sample positive examples\n",
    "            batch_samples = samples[offset:offset + batch_size]\n",
    "            sentences = batch_samples[:, 0]\n",
    "            movie_indices = batch_samples[:, 1]\n",
    "            X_sent.extend(sentences)\n",
    "            X_movie.extend(movie_indices)\n",
    "            y_out.extend([1]*batch_size)\n",
    "            \n",
    "            # Sample negative examples\n",
    "            keep_indx =  np.random.choice(ind, batch_size*n_neg, replace=False)\n",
    "            neg_samples = samples[keep_indx]\n",
    "            sentences = neg_samples[:, 0]\n",
    "            movie_indices = np.repeat(movie_indices, n_neg)\n",
    "            X_sent.extend(sentences)\n",
    "            X_movie.extend(movie_indices)\n",
    "            y_out.extend([0]*(batch_size*n_neg))\n",
    "             \n",
    "            # Pad zeros\n",
    "            X_sent = pad_sequences(X_sent, maxlen=max_len)\n",
    "             \n",
    "            yield sk_shuffle(X_sent.reshape(-1, max_len, 1), np.array(X_movie), np.array(y_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = generator(X_plots_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((192, 100, 1), (192,), (192,))"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sent, X_movies, y = next(t)\n",
    "\n",
    "X_sent.shape, X_movies.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=Tokenizer(), min_df = 10)\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(df[\"Plot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "f = np.array(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_movie_terms(x, top_n=50):\n",
    "    try:\n",
    "        i = df.query(\"Title == @x\").index[0]\n",
    "        print(df.iloc[i][\"Title\"])\n",
    "        print(\"Director: %s\" %df.iloc[i][\"Director\"])\n",
    "        print(\"Genre: %s\" %df.iloc[i][\"Genre\"])\n",
    "        print(\"\\nTop Terms\")\n",
    "        sorted_indices = np.array(X_tfidf[i].todense()).argsort()\n",
    "\n",
    "        print(f[sorted_indices].flatten()[::-1][:top_n])\n",
    "        print(\"\\n\")\n",
    "    except IndexError:\n",
    "        print(\"Movie Title Not Found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_movie_terms(\"Get Out\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    On May 26, 1987, Jenna Rink, a gawky girl, yea...\n",
       "11    The film opens with a clown (Buscemi) whose wi...\n",
       "12    Ex-convicts Emil Slovak (Karel Roden) and Oleg...\n",
       "13    The movie starts with Dylan Branson (Michiel H...\n",
       "14    Real estate agent Frank Mollard won't admit it...\n",
       "15    The film starts with Diana Watts (Lindsay Burd...\n",
       "16    In the late 22nd century, rising sea levels fr...\n",
       "17    Senior college student Katie Burke (Holmes) is...\n",
       "18    The film follows Curtis Clemins (Clint Palmer)...\n",
       "19    When a widowed reporter is informed by an FBI ...\n",
       "20    The film begins in an unspecified year of the ...\n",
       "21    Adam Raki (Dancy) is a young man with Asperger...\n",
       "22    Master thief Max Burdett (Pierce Brosnan) and ...\n",
       "23    After a reckless lie sets off a catastrophic c...\n",
       "24    Micha and Charlotte are a couple who have rece...\n",
       "25    Angst tells the story of a group of horror fil...\n",
       "26    When high-flying 27-year-old[2] Melbourne base...\n",
       "27    While escaping a political prison on a mining ...\n",
       "28    In the midst of the 2008 financial crisis, a p...\n",
       "29    Babel focuses on four interrelated sets of sit...\n",
       "30    A 20-year-old man named Joseph \"Jody\" Summers ...\n",
       "31    Kate Holbrook (Tina Fey) is a successful singl...\n",
       "32    Troubled psychotherapist Peter Bower suffers f...\n",
       "33    When a mission to retrieve a stolen suitcase b...\n",
       "34    Morris Buttermaker (Billy Bob Thornton) is a w...\n",
       "35    When fast talking, petty thief and hustler Alv...\n",
       "36    The movie opens with a hungover lifeguard, Jos...\n",
       "37    Eleven year old Randy Daytona becomes anxious ...\n",
       "38    Since the events of the previous film, Calvin ...\n",
       "39    Clare (Teresa Palmer), a young Australian back...\n",
       "40    Josh and Cin meet at a party in Sydney three d...\n",
       "41    The Torquay Tigers are a successful team playi...\n",
       "Name: Plot, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[10:42][\"Plot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tokenize_text(df.iloc[0][\"Plot\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neal',\n",
       " 'asks',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'policemen',\n",
       " 'who',\n",
       " 'he',\n",
       " 'was',\n",
       " 'and',\n",
       " 'replies',\n",
       " 'that',\n",
       " 'he',\n",
       " 'was',\n",
       " 'a',\n",
       " 'st.',\n",
       " 'louis',\n",
       " 'law',\n",
       " 'school',\n",
       " 'student',\n",
       " 'who',\n",
       " 'went',\n",
       " 'insane',\n",
       " 'and',\n",
       " 'murdered',\n",
       " 'his',\n",
       " 'own',\n",
       " 'father']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-da10cdbb2773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-bcebf6f683bd>\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(samples, batch_size, neg_samples)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mX_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0my_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0msk_shuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "list(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Out\n",
      "Jordan Peele\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['chris', 'rose', 'georgina', 'missy', 'logan', 'rod', 'walter',\n",
       "       'the', 'jeremy', 'black', 'dean', 'white', 'to', 'hudson', 'and',\n",
       "       'a', 'he', 'sunken', 'his', 's', 'awakens', 'hypnosis', 'deer',\n",
       "       'estate', 'but', 'flash', 'roman', 'phone', 'possessed', 'him',\n",
       "       'in', 'chair', 'of', 'photo', 'house', 'jim', 'family', 'with',\n",
       "       'goes', 'hypnotherapy', 'antlers', 'behavior', 'neurosurgeon',\n",
       "       'strange', 'car', 'into', 'people', 'gettogether', 'contradicting',\n",
       "       'unplugs'], dtype='<U20')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generator(samples, batch_size = 32, angle_offset = 0.2):\n",
    "    num_samples = len(samples)\n",
    "    while 1:\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset + batch_size]\n",
    "            \n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                # Center Image\n",
    "                name = \"./IMG/\" + batch_sample[0].split(\"\\\\\")[-1]\n",
    "                center_image = cv2.cvtColor(cv2.imread(name), cv2.COLOR_BGR2RGB)\n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                \n",
    "                # Flip image\n",
    "                images.append(np.fliplr(center_image))\n",
    "                angles.append(-center_angle)\n",
    "                \n",
    "                # Left Image\n",
    "                name = \"./IMG/\" + batch_sample[1].split(\"\\\\\")[-1]\n",
    "                left_image = cv2.cvtColor(cv2.imread(name), cv2.COLOR_BGR2RGB)\n",
    "                left_angle = float(batch_sample[3]) + angle_offset\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                \n",
    "                # Flip image\n",
    "                images.append(np.fliplr(left_image))\n",
    "                angles.append(-left_angle)\n",
    "                \n",
    "                \n",
    "                # Right Image\n",
    "                name = \"./IMG/\" + batch_sample[2].split(\"\\\\\")[-1]\n",
    "                right_image = cv2.cvtColor(cv2.imread(name), cv2.COLOR_BGR2RGB)\n",
    "                right_angle = float(batch_sample[3]) - angle_offset\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "                \n",
    "                # Flip image\n",
    "                images.append(np.fliplr(right_image))\n",
    "                angles.append(-right_angle)\n",
    "                \n",
    "                \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sk_shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = tokenize_text(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['she',\n",
       " 'has',\n",
       " 'her',\n",
       " 'mind',\n",
       " 'set',\n",
       " 'on',\n",
       " 'finding',\n",
       " 'a',\n",
       " 'tall',\n",
       " 'strong',\n",
       " 'man',\n",
       " 'to',\n",
       " 'marry',\n",
       " 'one',\n",
       " 'that',\n",
       " 'can',\n",
       " 'wear',\n",
       " 'a',\n",
       " 'trojan',\n",
       " 'shirt',\n",
       " 'with',\n",
       " 'a',\n",
       " 'neck',\n",
       " 'size']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_plots = []\n",
    "for plot in df[\"Plot\"].iloc[:10]:\n",
    "    X_plots.append(tokenize_text(plot))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=np.array(X_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_finalize__',\n",
       " '__array_interface__',\n",
       " '__array_prepare__',\n",
       " '__array_priority__',\n",
       " '__array_struct__',\n",
       " '__array_ufunc__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__complex__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__ilshift__',\n",
       " '__imatmul__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rlshift__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__rpow__',\n",
       " '__rrshift__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__xor__',\n",
       " 'all',\n",
       " 'any',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argpartition',\n",
       " 'argsort',\n",
       " 'astype',\n",
       " 'base',\n",
       " 'byteswap',\n",
       " 'choose',\n",
       " 'clip',\n",
       " 'compress',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'copy',\n",
       " 'ctypes',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'diagonal',\n",
       " 'dot',\n",
       " 'dtype',\n",
       " 'dump',\n",
       " 'dumps',\n",
       " 'fill',\n",
       " 'flags',\n",
       " 'flat',\n",
       " 'flatten',\n",
       " 'getfield',\n",
       " 'imag',\n",
       " 'item',\n",
       " 'itemset',\n",
       " 'itemsize',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'newbyteorder',\n",
       " 'nonzero',\n",
       " 'partition',\n",
       " 'prod',\n",
       " 'ptp',\n",
       " 'put',\n",
       " 'ravel',\n",
       " 'real',\n",
       " 'repeat',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'round',\n",
       " 'searchsorted',\n",
       " 'setfield',\n",
       " 'setflags',\n",
       " 'shape',\n",
       " 'size',\n",
       " 'sort',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'strides',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'take',\n",
       " 'tobytes',\n",
       " 'tofile',\n",
       " 'tolist',\n",
       " 'tostring',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'var',\n",
       " 'view']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-659b7e722c95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "d.ravel().tolist().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movies_venv",
   "language": "python",
   "name": "movies_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
